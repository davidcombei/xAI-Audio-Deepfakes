import torch
import torch.nn as nn
import torch.nn.functional as F
import torchaudio

# from ADDvisor import audioprocessor

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


from audioprocessor import AudioProcessor
from classifier_embedder import TorchLogReg, TorchScaler

audio_processor = AudioProcessor()
torch_logreg = TorchLogReg().to(device)
torch_scaler = TorchScaler().to(device)


class LMACLoss(nn.Module):
    def __init__(self, reg_w_tv=0.00, w_in=4, w_out=0.5):
        super(LMACLoss, self).__init__()
        self.reg_w_tv = reg_w_tv
        self.w_in = w_in
        self.w_out = w_out


    def loss_function(self, y_band_rel, y_band_irrel, phase, class_pred):  # , weights=None):

        
#        bands = audio_processor.get_freq_bands(magnitude, n_fft=1024)
        y_rel_band_reconstructed = y_band_rel * torch.exp(1j * phase)
        y_irrel_band_reconstructed = y_band_irrel * torch.exp(1j * phase)
        y_rel = audio_processor.compute_invert_stft(y_rel_band_reconstructed)
        y_irrel = audio_processor.compute_invert_stft(y_irrel_band_reconstructed)
        features_rel = audio_processor.extract_features(y_rel)
        features_irr = audio_processor.extract_features(y_irrel)
        features_rel = torch.mean(features_rel, dim=1)
        features_irr = torch.mean(features_irr, dim=1)
        rel_logits, _ = torch_logreg(features_rel)
        irr_logits, _ = torch_logreg(features_irr)

        l_in = F.binary_cross_entropy_with_logits(
            rel_logits, class_pred
        )  # .to(device))
        l_out = F.binary_cross_entropy_with_logits(irr_logits, 1 - class_pred)



        losses = torch.stack([l_in, l_out])  # , reg_l1])

        total_loss = self.w_in * l_in + self.w_out * l_out 

        return total_loss, losses  # , self.w
